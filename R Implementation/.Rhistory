var_fstat
var_fstat <- as.numeric(rep(NA, times = ncol(df_ind_col)))
names(var_fstat) <- colnames(df_ind_col)
var_fstat <- lapply(names(var_fstat), function(x) {
lm(substitute(i ~ success_1_to_1, list(i = as.name(x))), data = df2_var)$fstatistic[1]
})
var_fstat
a <- lapply(names(var_fstat), function(x) {
lm(substitute(i ~ success_1_to_1, list(i = as.name(x))), data = df2_var)$fstatistic[1]
})
a
a <- lapply(names(var_fstat), function(x) {
lm(substitute(i ~ success_1_to_1, list(i = as.name(x))), data = df2_var)$fstatistic[1]
})
a <- lapply(names(var_fstat), function(x) {
lm(substitute(i ~ success_1_to_1, list(i = as.name(x))), data = df2_var)$fstatistic[1]
})
a <- lapply(names(var_fstat), function(x) {
lm(substitute(i ~ success_1_to_1, list(i = as.name(x))), data = df2_var)
})
a
var_fstat <- lapply(names(var_fstat), function(x) {
lm(substitute(i ~ success_1_to_1, list(i = as.name(x))), data = df2_var)
})
var_fstat <- as.numeric(rep(NA, times = ncol(df_ind_col)))
names(var_fstat) <- colnames(df_ind_col)
var_fstat
var_fstat <- lapply(names(var_fstat), function(x) {
lm(substitute(i ~ success_1_to_1, list(i = as.name(x))), data = df2_var)
})
var_fstat
var_fstat <- lapply(names(var_fstat), function(x) {
lm(substitute(i ~ success_1_to_1, list(i = as.name(x))), data = df2_var)$fstatistic
})
var_fstat
lm(budget ~ success_1_to_1, data = df2_var)
colnames(df2_var)
df2 <- df1[,c(32, 7:24, 30, 34:53)]
##Standardize numerical columns
df3 <- scale(df1[, c(5:6, 27:29, 31, 33)])
##Merge the two dataframes
df4 <- cbind(df2, df3)
colnames(df4)
df_ind_col <- df4[,-1]
df_dep_col <- df4[, 1]
var_fstat <- as.numeric(rep(NA, times = ncol(df_ind_col)))
names(var_fstat) <- colnames(df_ind_col)
lm(budget ~ success_1_to_1, data = df2_var)
lm(budget ~ success_1_to_1, data = df4)
lm(budget ~ success_1_to_1, data = df4)$fstatistic
var_fstat <- lapply(names(var_fstat), function(x) {
summary(lm(substitute(i ~ success_1_to_1, list(i = as.name(x))), data = df4))$fstatistic[1]
})
var_fstat
var_fstat <- as.numeric(rep(NA, times = ncol(df_ind_col)))
names(var_fstat) <- colnames(df_ind_col)
var_fstat
var_fstat <- lapply(names(var_fstat), function(x) {
summary(lm(substitute(i ~ success_1_to_1, list(i = as.name(x))), data = df4))$fstatistic[1]
})
var_fstat
names(var_fstat) <- colnames(df_ind_col)
var_fstat
sorted_fstat <- sort(var_fstat, decreasing = T)
var_fstat
str(var_fstat)
for (i in 1:ncol(df_ind_col)){
var_fstat[i] <- summary(lm(substitute(i ~ success_1_to_1,
list(i = as.name(names(var_fstat)[i]))),
data = df4))$fstatistic[1]
}
var_fstat
sorted_fstat <- sort(var_fstat, decreasing = T)
var_fstat
str(var_fstat)
var_fstat[1]
var_fstat[2]
list(var_fstat)
for (i in 1:ncol(df_ind_col)){
var_fstat[[i]] <- summary(lm(substitute(i ~ success_1_to_1,
list(i = as.name(names(var_fstat)[i]))),
data = df4))$fstatistic[1]
}
var_fstat
for (i in 1:ncol(df_ind_col)){
var_fstat[i] <- summary(lm(substitute(i ~ success_1_to_1,
list(i = as.name(names(var_fstat)[i]))),
data = df4))$fstatistic[1]
}
var_fstat
var_fstat[1]
var_fstat[,1]
sort(var_fstat, decreasing = T)
str(var_fstat)
sort.list(var_fstat, decreasing = T)
sort.list(var_fstat)
head(var_fstat)
unlist(var_fstat)
sort(unlist(var_fstat))
sort(unlist(var_fstat), decreasing = T)
sorted_df <- sort(unlist(var_fstat), decreasing = T)
names(sorted_df)[1:17]
best_17 <- names(sorted_df)[1:17]
df_17 <- cbind(df_dep_col, df4[, best_17])
model_rectangular_17 <- train(
success_1_to_1 ~.,
data = df_17,
method = "kknn",
trControl = trainControl("cv", number = 10),
tuneGrid = expand.grid(kmax = 15:50,
distance = 2,
kernel = c('rectangular')))
colnames(df_17)
colnames(df_dep_col)
colnames(df4)
df_dep_col <- df4[, 1]
colnames(df_dep_col)
df_dep_col
df_ind_col
colnames(df_17)[1] <- 'success_1_to_1'
colnames(df_17)
model_rectangular_17 <- train(
success_1_to_1 ~.,
data = df_17,
method = "kknn",
trControl = trainControl("cv", number = 10),
tuneGrid = expand.grid(kmax = 15:50,
distance = 2,
kernel = c('rectangular')))
set.seed(1000)
inTrain <- createDataPartition(y = df_17[,'success_1_to_1'], list = FALSE, p = .8)
train_17 <- df_17[inTrain,]
test_17 <- df_17[-inTrain,]
model_rectangular_17 <- train(
success_1_to_1 ~.,
data = train_17,
method = "kknn",
trControl = trainControl("cv", number = 10),
tuneGrid = expand.grid(kmax = 15:50,
distance = 2,
kernel = c('rectangular')))
df1 <- read.csv('/Users/Sunny/Github/CSP571_Movie_Profits_Project/5_merged_with_holidays.csv', stringsAsFactors = T)
##Convert classification to factors
df1$success_1_to_1 <- as.factor(df1$success_1_to_1)
##Extract categorical variables and other variables that we do not want to standardize
df2 <- df1[,c(32, 7:24, 30, 34:53)]
##Standardize numerical columns
df3 <- scale(df1[, c(5:6, 27:29, 31, 33)])
##Merge the two dataframes
df4 <- cbind(df2, df3)
##Partition into 80%, and 20% test, constrained to its chronological ordering
inTrain <- createDataPartition(y = df4[,'success_1_to_1'], list = FALSE, p = .8)
train <- df4[inTrain,]
test <- df4[-inTrain,]
train_set <- train[, -c(1)]
train_label_class <- train[, 1]
test <- df5[c((splitRow+1):nrow(df5)),]
test_set <- test[, -c(1)]
test_label_class <- test[, 1]
###############################################################
colnames(df_17)
train_17 <- cbind(train[, 'success_1_to_1'], train[, best_17])
###############################################################
colnames(train_17)
colnames(train_17)[1] <- 'success_1_to_1'
e
model_rectangular_17 <- train(
success_1_to_1 ~.,
data = train_17,
method = "kknn",
trControl = trainControl("cv", number = 10),
tuneGrid = expand.grid(kmax = 15:50,
distance = 2,
kernel = c('rectangular')))
model_rectangular_17 <- train(
success_1_to_1 ~.,
data = train_17,
method = "kknn",
trControl = trainControl("cv", number = 10),
tuneGrid = expand.grid(kmax = 15:50,
distance = 2,
kernel = c('rectangular')))
df1_elastic <- read.csv('/Users/Sunny/Github/CSP571_Movie_Profits_Project/elastic_net_final_dataset.csv', stringsAsFactors = T)
##Convert classification to factors
df1_elastic$success_1_to_1 <- as.factor(df1$success_1_to_1)
colnames(df1_elastic)
plot(model_rectangular_17)
model_rectangular_17$bestTune
mean(model_rectangular_17$results$Accuracy)
model_rectangular$bestTune
train_elastic <- df1_elastic[inTrain,]
test_elastic <- df1_elastic[-inTrain,]
model_rectangular <- train(
success_1_to_1 ~.,
data = train_elastic,
method = "kknn",
trControl = trainControl("cv", number = 10),
tuneGrid = expand.grid(kmax = 15:50,
distance = 2,
kernel = c('rectangular')))
colnames(train_elastic)
df1_elastic <- df1_elastic[2:20]
##Convert classification to factors
df1_elastic$success_1_to_1 <- as.factor(df1$success_1_to_1)
str(df1_elastic)
##Convert classification to factors
df1_elastic$success_1_to_1 <- as.factor(df1_elastic$success_1_to_1)
df1_elastic <- read.csv('/Users/Sunny/Github/CSP571_Movie_Profits_Project/elastic_net_final_dataset.csv', stringsAsFactors = T)
df1_elastic <- df1_elastic[2:20]
##Convert classification to factors
df1_elastic$success_1_to_1 <- as.factor(df1_elastic$success_1_to_1)
train_elastic <- df1_elastic[inTrain,]
test_elastic <- df1_elastic[-inTrain,]
model_rectangular <- train(
success_1_to_1 ~.,
data = train_elastic,
method = "kknn",
trControl = trainControl("cv", number = 10),
tuneGrid = expand.grid(kmax = 15:50,
distance = 2,
kernel = c('rectangular')))
View(train_elastic)
df2_elastic <-
colnames(df1_elastic)
source('C:/Users/Sunny/Github/CSP571_Movie_Profits_Project/KNN_after_selection.R', echo=TRUE)
df2_elastic <-
colnames(df1_elastic)
colnames(df1_elastic)
df2_elastic <- df1_elastic[19, 3:11, 15, 17:18]
df3_elastic <- df1_elastic[1:2, 12:14, 16]
df3_elastic <- scale(df1_elastic[1:2, 12:14, 16])
source('C:/Users/Sunny/Github/CSP571_Movie_Profits_Project/KNN_Variable_Selection.R')
df3_elastic <- scale(df1_elastic[1:2, 12:14, 16])
df4_elastic <- cbind(df2_elastic, df3_elastic)
colnames(df4_elastic)
df1_elastic <- read.csv('/Users/Sunny/Github/CSP571_Movie_Profits_Project/elastic_net_final_dataset.csv', stringsAsFactors = T)
df1_elastic <- df1_elastic[2:20]
##Convert classification to factors
df1_elastic$success_1_to_1 <- as.factor(df1_elastic$success_1_to_1)
colnames(df1_elastic)
df2_elastic <- df1_elastic[19, 3:11, 15, 17:18]
df2_elastic <- df1_elastic[, c(19, 3:11, 15, 17:18)]
df3_elastic <- scale(df1_elastic[, c(1:2, 12:14, 16)])
df4_elastic <- cbind(df2_elastic, df3_elastic)
colnames(df4_elastic)
train_elastic <- df4_elastic[inTrain,]
train_elastic
test_elastic <- df4_elastic[-inTrain,]
colnames(train_elastic)
model_rectangular_elastic <- train(
success_1_to_1 ~.,
data = train_elastic,
method = "kknn",
trControl = trainControl("cv", number = 10),
tuneGrid = expand.grid(kmax = 15:50,
distance = 2,
kernel = c('rectangular')))
sapply(train_elastic, function(y): sum(is.na(y))
sapply(train_elastic, function(y) sum(length(which(is.na(y)))))
sapply(df1_elastic, function(y) sum(length(which(is.na(y)))))
df1_elastic <- read.csv('/Users/Sunny/Github/CSP571_Movie_Profits_Project/elastic_net_final_dataset.csv', stringsAsFactors = T)
sapply(df1_elastic, function(y) sum(length(which(is.na(y)))))
df1_elastic <- df1_elastic[2:20]
sapply(df1_elastic, function(y) sum(length(which(is.na(y)))))
##Convert classification to factors
df1_elastic$success_1_to_1 <- as.factor(df1_elastic$success_1_to_1)
sapply(df1_elastic, function(y) sum(length(which(is.na(y)))))
df2_elastic <- df1_elastic[, c(19, 3:11, 15, 17:18)]
sapply(df1_elastic, function(y) sum(length(which(is.na(y)))))
sapply(df2_elastic, function(y) sum(length(which(is.na(y)))))
df3_elastic <- scale(df1_elastic[, c(1:2, 12:14, 16)])
sapply(df3_elastic, function(y) sum(length(which(is.na(y)))))
df3 <- scale(df1[, c(5:6, 27:29, 31, 33)])
df3
df3_elastic
df4_elastic <- cbind(df2_elastic, df3_elastic)
sapply(df4_elastic, function(y) sum(length(which(is.na(y)))))
model_rectangular_elastic <- train(
success_1_to_1 ~.,
data = train_elastic,
method = "kknn",
trControl = trainControl("cv", number = 10),
tuneGrid = expand.grid(kmax = 15:50,
distance = 2,
kernel = c('rectangular')))
model_rectangular_elastic <- train(
success_1_to_1 ~.,
data = train_elastic,
method = "kknn",
trControl = trainControl("cv", number = 10),
tuneGrid = expand.grid(kmax = 15:50,
distance = 2,
kernel = c('rectangular')))
sapply(df4_elastic, function(y) sum(length(which(is.na(y)))))
str(df4_elastic)
model_rectangular_elastic <- train(
success_1_to_1 ~.,
data = train_elastic,
method = "kknn",
trControl = trainControl("cv", number = 10),
tuneGrid = expand.grid(kmax = 15:50,
distance = 2,
kernel = c('rectangular')))
df4_elastic
model_rectangular_elastic <- train(
success_1_to_1 ~.,
data = train_elastic,
method = "kknn",
trControl = trainControl("cv", number = 10),
tuneGrid = expand.grid(kmax = 15:50,
distance = 2,
kernel = c('rectangular')))
View(df1_elastic)
View(df2_elastic)
View(df3_elastic)
View(df4)
View(df4_elastic)
str(df4)
str(df4_elastic)
df1_elastic <- df1_elastic[2:20]
##Convert classification to factors
df1_elastic$success_1_to_1 <- as.factor(df1_elastic$success_1_to_1)
source('C:/Users/Sunny/Github/CSP571_Movie_Profits_Project/KNN_after_selection.R', echo=TRUE)
df1_elastic <- read.csv('/Users/Sunny/Github/CSP571_Movie_Profits_Project/elastic_net_final_dataset.csv', stringsAsFactors = T)
df1_elastic <- df1_elastic[2:20]
##Convert classification to factors
df1_elastic$success_1_to_1 <- as.factor(df1_elastic$success_1_to_1)
df3_elastic <- scale(df1_elastic[, c(1:2, 12:14, 16)])
df4_elastic <- cbind(df2_elastic, df3_elastic)
df2_elastic <- df1_elastic[, c(19, 3:11, 15, 17:18)]
train_elastic <- df4_elastic[inTrain,]
test_elastic <- df4_elastic[-inTrain,]
sapply(df4_elastic, function(y) sum(length(which(is.na(y)))))
str(train_elastic)
model_rectangular_elastic <- train(
success_1_to_1 ~.,
data = train_elastic,
method = "kknn",
trControl = trainControl("cv", number = 10),
tuneGrid = expand.grid(kmax = 15:50,
distance = 2,
kernel = c('rectangular')))
##Rectangular / Non-weighted
model_rectangular <- train(
success_1_to_1 ~.,
data = train,
method = "kknn",
trControl = trainControl("cv", number = 10),
tuneGrid = expand.grid(kmax = 15:50,
distance = 2,
kernel = c('rectangular')))
inTrain <- createDataPartition(y = df4_elastic[,'success_1_to_1'], list = FALSE, p = .8)
train_elastic <- df4_elastic[inTrain,]
test_elastic <- df4_elastic[-inTrain,]
model_rectangular_elastic <- train(
success_1_to_1 ~.,
data = train_elastic,
method = "kknn",
trControl = trainControl("cv", number = 10),
tuneGrid = expand.grid(kmax = 15:50,
distance = 2,
kernel = c('rectangular')))
##K=15 is optimal
plot(model_rectangular_elastic)
model_rectangular_elastic$bestTune
mean(model_rectangular_elastic$results$Accuracy)
max(model_rectangular_elastic$results$Accuracy)
max(model_rectangular_17$results$Accuracy)
model_kernel_elastic <- train(
success_1_to_1 ~.,
data = train_elastic,
method = "kknn",
trControl = trainControl("cv", number = 10),
tuneGrid = expand.grid(kmax = 15:50,
distance = 2,
kernel = c('rectangular', 'triangular', 'gaussian', 'epanechnikov')))
plot(model_kernel_elastic)
max(model_kernel_elastic$results$Accuracy)
model_kernel_elastic$bestTune
model_epan_elastic <- train(
success_1_to_1 ~.,
data = train_elastic,
method = "kknn",
trControl = trainControl("cv", number = 10),
tuneGrid = expand.grid(kmax = 38,
distance = c(1:5),
kernel = c('gaussian')))
model_gaussian_elastic <- train(
success_1_to_1 ~.,
data = train_elastic,
method = "kknn",
trControl = trainControl("cv", number = 10),
tuneGrid = expand.grid(kmax = 38,
distance = c(1:5),
kernel = c('gaussian')))
plot(model_gaussian_elastic)
model_gaussian_elastic$bestTune
pred_gaussian_elastic <- predict.train(object = model_gaussian_elastic, test_elastic)
confusionMatrix(pred_gaussian_elastic, reference = test_elastic$success_1_to_1, positive = '1')
source('C:/Users/Sunny/Github/CSP571_Movie_Profits_Project/KNN_Variable_Selection.R')
setwd('/Users/Sunny/Desktop/R Files/CSP 554 - Big Data - Final Project')
auto <- read.csv('auto-mpg.csv', stringsAsFactors = F)
str(auto)
summary(auto)
colnames(auto) <- c('label', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration',
'model_year', 'origin', 'car_name')
auto <- auto[auto['cylinders']!=3,]
auto <- auto[auto['cylinders']!=5,]
summary(auto)
#Fill missing horsepower values with mean cylinders
auto$horsepower[is.na(auto$horsepower)] <- mean(auto$horsepower[auto$horsepower > 0])
#Drop car names
auto <- auto[-1]
head(auto)
auto <- read.csv('auto-mpg.csv', stringsAsFactors = F)
colnames(auto) <- c('label', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration',
'model_year', 'origin', 'car_name')
summary(auto)
head(auto)
#Drop car names
auto <- auto[-c('car_name')]
#Drop car names
auto <- auto[-9]
#Drop cars with 3 or 5 cylinders
auto <- auto[auto['cylinders']!=3,]
auto <- auto[auto['cylinders']!=5,]
#Fill missing horsepower values with mean cylinders
auto$horsepower[is.na(auto$horsepower)] <- mean(auto$horsepower[auto$horsepower > 0])
head(auto)
summary(auto)
library(caret)
#Convert certain categorical columns to factors
auto$cylinders <- as.factor(auto$cylinders)
auto$model_year <- as.factor(auto$model_year)
auto$origin <- as.factor(auto$origin)
summary(auto)
#Dummify the factor variables
dmy <- dummyVars("~.", data = auto)
dmy
df <- data.frame(predict(dmy, newdata = auto))
head(df)
set.seed(7)
#Divide to train and test sets
inTraining <- createDataPartition(df$label, p = 0.75, list = F)
train <- df[inTraining, ]
test <- df[-inTraining, ]
nrow(auto)
nrow(train)
nrow(test)
linear_model <- train(
label~., data = train, method = "glmnet",
trControl = trainControl("cv", number = 3),
tuneGrid = expand.grid(lambda = c(0, 0.25, 0.5), alpha = c(0, 0.25, 0.5))
)
summary(df)
str(df)
sum(is.na(df$label))
summary(inTraining)
summary(train)
summary(auto)
sum(is.na(train$label))
sapply(train, function(y): sum(is.na(y)))
sapply(train, function(y) sum(is.na(y)))
linear_model <- train(
label~., data = train, method = "glmnet",
trControl = trainControl("cv", number = 3),
tuneGrid = expand.grid(lambda = c(0, 0.25, 0.5), alpha = c(0, 0.25, 0.5))
)
train$label
train
sum(is.na(train$label))
auto <- read.csv('auto-mpg.csv', stringsAsFactors = F)
colnames(auto) <- c('label', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration',
'model_year', 'origin', 'car_name')
#Drop cars with 3 or 5 cylinders
auto <- auto[auto['cylinders']!=3,]
auto <- auto[auto['cylinders']!=5,]
#Fill missing horsepower values with mean cylinders
auto$horsepower[is.na(auto$horsepower)] <- mean(auto$horsepower[auto$horsepower > 0])
auto$horsepower
sum(is.na(auto$horsepower))
#Fill missing horsepower values with mean cylinders
auto$horsepower[is.na(auto$horsepower)] <- mean(auto$horsepower[!is.na(auto$horsepower)])
sum(is.na(auto$horsepower))
#Drop car names
auto <- auto[-9]
#Convert certain categorical columns to factors
auto$cylinders <- as.factor(auto$cylinders)
auto$model_year <- as.factor(auto$model_year)
auto$origin <- as.factor(auto$origin)
#Dummify the factor variables
dmy <- dummyVars("~.", data = auto)
df <- data.frame(predict(dmy, newdata = auto))
#Divide to train and test sets
inTraining <- createDataPartition(df$label, p = 0.75, list = F)
train <- df[inTraining, ]
test <- df[-inTraining, ]
sapply(train, function(y) sum(is.na(y)))
##Linear Regression, Decision Tree, Random Forest, Gradient Boosted Trees
linear_model <- train(
label~., data = train, method = "glmnet",
trControl = trainControl("cv", number = 3),
tuneGrid = expand.grid(lambda = c(0, 0.25, 0.5), alpha = c(0, 0.25, 0.5))
)
install.packages('glmnet')
library(glmnet)
install.packages(glmnet)
library(installr)
updateR
install.packages('glmnet')
library(installr)
updateR()
